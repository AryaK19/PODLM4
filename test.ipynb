{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "c:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoProcessor , BarkModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"suno/bark-small\")\n",
    "# model = AutoModel.from_pretrained(\"suno/bark-small\")\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = BarkModel.from_pretrained(\"suno/bark-small\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\").to(device)\n",
    "model =  model.to_bettertransformer()\n",
    "\n",
    "\n",
    "voice_preset = \"v2/en_speaker_9\"\n",
    "\n",
    "inputs = processor(\"Hello, my name is Aditya. And, uh — and I like pizza. [laughs] But I also have other interests such as playing tic tac toe.\", voice_preset=voice_preset).to(device)\n",
    "inputs['attention_mask'] = inputs['input_ids'].ne(processor.tokenizer.pad_token_id).long().to(device)\n",
    "audio_array = model.generate(**inputs)\n",
    "audio_array = audio_array.cpu().numpy().squeeze()\n",
    "import scipy\n",
    "\n",
    "sample_rate = model.generation_config.sample_rate\n",
    "scipy.io.wavfile.write(\"bark_out.wav\", rate=sample_rate, data=audio_array.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "import soundfile as sf\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "attn_implementation = \"flash_attention_2\" \n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-mini-v1\",attn_implementation=attn_implementation,torch_dtype=torch.float16).to(device)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-mini-v1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'todtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m prompt_input_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m generation \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m=\u001b[39minput_ids, prompt_input_ids\u001b[38;5;241m=\u001b[39mprompt_input_ids)\n\u001b[1;32m----> 8\u001b[0m audio_arr \u001b[38;5;241m=\u001b[39m \u001b[43mgeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtodtype\u001b[49m(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      9\u001b[0m sf\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparler_tts_out.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, audio_arr, model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msampling_rate)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'todtype'"
     ]
    }
   ],
   "source": [
    "prompt = \"Hello, my name is Suno. And, uh — and I like pizza. [laughs] But I also have other interests such as playing tic tac toe.\"\n",
    "description = \"A female speaker delivers a slightly expressive and animated speech with a moderate speed and pitch. The recording is of very high quality, with the speaker's voice sounding clear and very close up.\"\n",
    "\n",
    "input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "audio_arr = generation.cpu().numpy().squeeze().todtype(np.float32)\n",
    "sf.write(\"parler_tts_out.wav\", audio_arr, model.config.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating podcast...\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "PODLM = ollama.Client()\n",
    "print(\"Generating podcast...\")\n",
    "podcast = PODLM.generate(model=\"PODLM4\" ,prompt='''AI based SWOC analysis of student using academic progress\n",
    "Vishwakarma Institute of Information Technology\n",
    "Course: TY Project\n",
    "Guide: Prof. Priya Shelke\n",
    "Abstract\n",
    "It is time consuming and difficult to analyze your weaknesses and come up with a good solution.\n",
    "At the same time some students do not know the concrete areas where they should improve themselves\n",
    "since the number of academic jobs required them time to finish their assignments. Furthermore, without\n",
    "explicit guidance from the teacher, students cannot figure out the hierarchy of improvement or which source\n",
    "is good or not. Furthermore, students may have difficulty noticing their own long-term growth when they\n",
    "have no benchmarks against which to measure their efforts - it may appear that their efforts aren't yielding\n",
    "the results they want. Without opportunities for self-reflection or personal feedback, students may be left\n",
    "wondering what they should do next, how to overcome their current difficulties, and so on.\n",
    "This project will focus on achieving a general web application that will enable students to selfassess their studies and get insights via a SWOC (Strengths, Weaknesses, Opportunities and Challenges)\n",
    "analysis. Through a machine learning algorithm, the analysis of the students' performance shall be\n",
    "conducted based on different parameters such as examinations performance, participation in competitions,\n",
    "project success rate among others and a grade will be given to the students respective to their performance.\n",
    "SWOC analysis will give specific, personalized recommendations to help students learn where they excel\n",
    "and where they struggle. Through this analysis, students will be able to allocate their efforts more wisely.\n",
    "The platform will also provide continuous progress reports in the form of dynamic visualizations of\n",
    "academic progress over time. Further, the application will include a chatbot system for the students to ask\n",
    "questions regarding improvements and different pathways which they can follow to achieve their dreams.''')\n",
    "print(podcast)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
